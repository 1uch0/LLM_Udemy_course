{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM4y8PbnBTWOgPb9Rj86218",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1uch0/LLM_Udemy_course/blob/main/RAG__Extracting_information_from_companies_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Expert Knowledge Worker\n",
        "\n",
        "### A question answering agent that is an expert knowledge worker\n",
        "### To be used by employees of Insurellm, an Insurance Tech company\n",
        "### The agent needs to be accurate and the solution should be low cost.\n",
        "\n",
        "This project will use RAG (Retrieval Augmented Generation) to ensure our question/answering assistant has high accuracy.\n",
        "\n",
        "This first implementation will use a simple, brute-force type of RAG..\n",
        "\n",
        "### Sidenote: Business applications of this week's projects\n",
        "\n",
        "RAG is perhaps the most immediately applicable technique of anything that we cover in the course! In fact, there are commercial products that do precisely what we build this week: nuanced querying across large databases of information, such as company contracts or product specs. RAG gives you a quick-to-market, low cost mechanism for adapting an LLM to your business area."
      ],
      "metadata": {
        "id": "omY_3ZwGgovT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install gradio\n",
        "#!pip install anthropic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMVkoaEQg3o0",
        "outputId": "41faec87-4368-419c-9adc-535a751989c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting anthropic\n",
            "  Downloading anthropic-0.49.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->anthropic) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->anthropic) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.27.2)\n",
            "Downloading anthropic-0.49.0-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: anthropic\n",
            "Successfully installed anthropic-0.49.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2DHTrOxglE7"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import io\n",
        "import glob\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from typing import List\n",
        "#from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "import google.generativeai as fenai\n",
        "#import anthropic\n",
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "import gradio as gr\n",
        "import json\n",
        "import anthropic\n",
        "import subprocess"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7Ch6TBHmRZX",
        "outputId": "3422e3bf-94de-4973-ccb9-b197bfb115a5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# price is a factor for our company, so we're going to use a low cost model\n",
        "\n",
        "MODEL = \"gpt-4o-mini\""
      ],
      "metadata": {
        "id": "Omf3ffQrgy5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = userdata.get('Open_AI_API') ##Open_AI_API It is the API key from OPEN_AI saved in your collab\n",
        "openai = OpenAI(api_key=api_key)\n",
        "openai_api_key = api_key\n",
        "\n",
        "claude = anthropic.Anthropic()\n",
        "\n",
        "OPENAI_MODEL = \"gpt-4o-mini\"\n",
        "CLAUDE_MODEL = \"claude-3-haiku-20240307\""
      ],
      "metadata": {
        "id": "BjaaG1hFhTpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# With massive thanks to student Dr John S. for fixing a bug in the below for Windows users!\n",
        "\n",
        "context = {}\n",
        "\n",
        "employees = glob.glob(\"/content/drive/MyDrive/Colab Notebooks/LLM Engineering course/knowledge-base/employees/*\")\n",
        "\n",
        "for employee in employees:\n",
        "    name = os.path.splitext(os.path.basename(employee))[0]  #Takes the name of the file\n",
        "    doc = \"\"\n",
        "    with open(employee, \"r\", encoding=\"utf-8\") as f:\n",
        "        doc = f.read()\n",
        "    context[name]=doc #open the files"
      ],
      "metadata": {
        "id": "QA1RnnUEhWRQ"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(employees)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VS9JcIwWl1Y2",
        "outputId": "43528c74-b6c7-4407-97a2-1836ffefedbe"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/MyDrive/Colab Notebooks/LLM Engineering course/knowledge-base/employees/Alex Thomson.md', '/content/drive/MyDrive/Colab Notebooks/LLM Engineering course/knowledge-base/employees/Samantha Greene.md', '/content/drive/MyDrive/Colab Notebooks/LLM Engineering course/knowledge-base/employees/Alex Harper.md', '/content/drive/MyDrive/Colab Notebooks/LLM Engineering course/knowledge-base/employees/Jordan K. Bishop.md', '/content/drive/MyDrive/Colab Notebooks/LLM Engineering course/knowledge-base/employees/Avery Lancaster.md', '/content/drive/MyDrive/Colab Notebooks/LLM Engineering course/knowledge-base/employees/Jordan Blake.md', '/content/drive/MyDrive/Colab Notebooks/LLM Engineering course/knowledge-base/employees/Oliver Spencer.md', '/content/drive/MyDrive/Colab Notebooks/LLM Engineering course/knowledge-base/employees/Alex Chen.md', '/content/drive/MyDrive/Colab Notebooks/LLM Engineering course/knowledge-base/employees/Samuel Trenton.md', '/content/drive/MyDrive/Colab Notebooks/LLM Engineering course/knowledge-base/employees/Emily Tran.md', '/content/drive/MyDrive/Colab Notebooks/LLM Engineering course/knowledge-base/employees/Emily Carter.md', '/content/drive/MyDrive/Colab Notebooks/LLM Engineering course/knowledge-base/employees/Maxine Thompson.md']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context[\"Alex Thomson\"]   #Keys are the last names of the employees"
      ],
      "metadata": {
        "id": "315McNt9hayh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "edc3376f-6319-4ae6-8977-a5788efdd576"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# HR Record\\n\\n# Alex Thomson\\n\\n## Summary\\n- **Date of Birth:** March 15, 1995  \\n- **Job Title:** Sales Development Representative (SDR)  \\n- **Location:** Austin, Texas  \\n\\n## Insurellm Career Progression\\n- **November 2022** - Joined Insurellm as a Sales Development Representative. Alex Thomson quickly adapted to the team, demonstrating exceptional communication and rapport-building skills.\\n- **January 2023** - Promoted to Team Lead for special projects due to Alex\\'s initiative in driving B2B customer outreach programs.  \\n- **August 2023** - Developed a training module for new SDRs at Insurellm, enhancing onboarding processes based on feedback and strategies that Alex Thomson pioneered.  \\n- **Current** - Continues to excel in the role, leading a small team of 5 SDRs while collaborating closely with the marketing department to identify new lead-generation strategies.  \\n\\n## Annual Performance History  \\n- **2022** - Rated as \"Exceeds Expectations.\" Alex Thomson achieved 150% of the sales target within the first three months.  \\n- **2023** - Rated \"Outstanding.\" Recognized for innovative lead-generation tactics which contributed to a 30% increase in qualified leads for the sales team.  \\n\\n### Highlights:\\n- Consistently maintained a 30-minute response time to inbound leads.\\n- Successfully coordinated webinars for product launches, which attracted over 2,000 potential customers.\\n\\n## Compensation History\\n- **2022**: Base Salary - $55,000 | Bonus - $5,000  \\n- **2023**: Base Salary - $65,000 | Bonus - $10,000 (for exceeding sales targets and exceptional teamwork)  \\n- **Projected for 2024**: Anticipated salary increase due to Alex Thomson\\'s significant contributions and successful completion of leadership training.\\n\\n## Other HR Notes\\n- Alex Thomson is an active member of the Diversity and Inclusion committee at Insurellm and has participated in various community outreach programs.  \\n- Alex has received external training on advanced CRM usage, which has subsequently improved team efficiency and productivity.\\n- Continuous professional development through attending sales conventions and workshops, with plans to pursue certification in Sales Enablement in 2024.\\n- Recognized by peers for promoting a supportive and high-energy team environment, often organizing team-building activities to enhance camaraderie within the SDR department. \\n\\n--- \\n**Comment:** Alex Thomson is considered a cornerstone of Insurellm’s sales team and has a bright future within the organization.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "products = glob.glob(\"/content/drive/MyDrive/Colab Notebooks/LLM Engineering course/knowledge-base/products/*\")\n",
        "\n",
        "for product in products:\n",
        "    name = product.split(os.sep)[-1][:-3]\n",
        "    doc = \"\"\n",
        "    with open(product, \"r\", encoding=\"utf-8\") as f:\n",
        "        doc = f.read()\n",
        "    context[name]=doc"
      ],
      "metadata": {
        "id": "FRaTcgb5lQOe"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7kT_ZgQnmH_",
        "outputId": "04690043-3ff4-4a6a-cb57-c2dff0066963"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['Alex Thomson', 'Samantha Greene', 'Alex Harper', 'Jordan K. Bishop', 'Avery Lancaster', 'Jordan Blake', 'Oliver Spencer', 'Alex Chen', 'Samuel Trenton', 'Emily Tran', 'Emily Carter', 'Maxine Thompson', 'Carllm', 'Rellm', 'Homellm', 'Markellm'])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"You are an expert in answering accurate questions about Insurellm, the Insurance Tech company. Give brief, accurate answers. If you don't know the answer, say so. Do not make anything up if you haven't been provided with relevant context.\""
      ],
      "metadata": {
        "id": "LVzf2EPenofi"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function that takes a message, any kind of message and interacto trhout the context and it is going to see if the product, name exist in context\n",
        "\n",
        "\n",
        "def get_relevant_context(message):\n",
        "    relevant_context = []\n",
        "    for context_title, context_details in context.items():\n",
        "        if context_title.lower() in message.lower():\n",
        "            relevant_context.append(context_details)\n",
        "    return relevant_context"
      ],
      "metadata": {
        "id": "_rclbaUynqzJ"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_relevant_context(\"Who is Alex Thomson?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxY5HwV6nslj",
        "outputId": "e4a45b64-641e-4091-92f8-53d1901a1df2"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_relevant_context(\"Who is Avery and what is carllm?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePCxxYVfnuE5",
        "outputId": "bd5968ef-5df5-4864-9c52-db3dcbd598ce"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['# Product Summary\\n\\n# Carllm\\n\\n## Summary\\n\\nCarllm is an innovative auto insurance product developed by Insurellm, designed to streamline the way insurance companies offer coverage to their customers. Powered by cutting-edge artificial intelligence, Carllm utilizes advanced algorithms to deliver personalized auto insurance solutions, ensuring optimal coverage while minimizing costs. With a robust infrastructure that supports both B2B and B2C customers, Carllm redefines the auto insurance landscape and empowers insurance providers to enhance customer satisfaction and retention.\\n\\n## Features\\n\\n- **AI-Powered Risk Assessment**: Carllm leverages artificial intelligence to analyze driver behavior, vehicle conditions, and historical claims data. This enables insurers to make informed decisions and set competitive premiums that reflect true risk profiles.\\n\\n- **Instant Quoting**: With Carllm, insurance companies can offer near-instant quotes to customers, enhancing the customer experience. The AI engine processes data in real-time, drastically reducing the time it takes to generate quotes.\\n\\n- **Customizable Coverage Plans**: Carllm allows insurers to create flexible and tailored insurance packages based on individual customer needs. This customization improves customer engagement and retention.\\n\\n- **Fraud Detection**: The product incorporates advanced analytics to identify potentially fraudulent claims, significantly reducing the risk of losses for insurance providers.\\n\\n- **Customer Insights Dashboard**: Carllm provides insurers with a powerful dashboard that offers deep insights into customer behavior, claims patterns, and market trends, enabling informed decision-making and strategic planning.\\n\\n- **Mobile Integration**: Carllm is designed to work seamlessly with mobile applications, providing both insurers and end-users access to policy management and claims reporting on the go.\\n\\n- **Automated Customer Support**: Leveraging AI chatbots, Carllm offers 24/7 customer support, helping to resolve inquiries quickly and efficiently, thus improving customer satisfaction.\\n\\n## Pricing\\n\\nCarllm is offered under a subscription-based pricing model tailored to meet the needs of insurance companies of all sizes. Our pricing tiers are designed to provide maximum flexibility and value:\\n\\n- **Basic Tier**: $1,000/month\\n  - Ideal for small insurance firms.\\n  - Access to core features and standard reporting.\\n\\n- **Professional Tier**: $2,500/month\\n  - For medium-sized companies.\\n  - All Basic Tier features plus advanced analytics and fraud detection.\\n\\n- **Enterprise Tier**: $5,000/month\\n  - Customized solutions for large insurance firms.\\n  - Comprehensive support, full feature access, and integration with existing systems.\\n\\nContact our sales team for a personalized quote and discover how Carllm can transform your auto insurance offerings!\\n\\n## 2025-2026 Roadmap\\n\\nIn our commitment to continuous improvement and innovation, Insurellm has outlined the following roadmap for Carllm:\\n\\n### Q1 2025: Launch Feature Enhancements\\n- **Expanded data integrations** for better risk assessment.\\n- **Enhanced fraud detection algorithms** to reduce losses.\\n\\n### Q2 2025: Customer Experience Improvements\\n- Launch of a new **mobile app** for end-users.\\n- Introduction of **telematics-based pricing** to provide even more tailored coverage options.\\n\\n### Q3 2025: Global Expansion\\n- Begin pilot programs for international insurance markets.\\n- Collaborate with local insurers to offer compliant, localized versions of Carllm.\\n\\n### Q4 2025: AI and Machine Learning Upgrades\\n- Implement next-gen machine learning models for predictive analysis.\\n- Roll out customer insights dashboard updates based on user feedback.\\n\\n### 2026: Scaling and Partnerships\\n- Increase partnerships with automakers for integrated insurance solutions.\\n- Enhance the **AI customer support system** to include multi-language support.\\n\\nCarllm is not just an auto insurance product; it is a transformative tool for the insurance industry. Join us on this exciting journey as we redefine the future of auto insurance with technology and customer-centric solutions.']"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add_context(message):\n",
        "    relevant_context = get_relevant_context(message)\n",
        "    if relevant_context:\n",
        "        message += \"\\n\\nThe following additional context might be relevant in answering this question:\\n\\n\"\n",
        "        for relevant in relevant_context:\n",
        "            message += relevant + \"\\n\\n\"\n",
        "    return message"
      ],
      "metadata": {
        "id": "c9PPnMRvnwgj"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(add_context(\"Who is Alex Thomson?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VONliB0NnyGY",
        "outputId": "533131b8-677c-4f3d-b207-56d896dcd740"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Who is Alex Thomson?\n",
            "\n",
            "The following additional context might be relevant in answering this question:\n",
            "\n",
            "# HR Record\n",
            "\n",
            "# Alex Thomson\n",
            "\n",
            "## Summary\n",
            "- **Date of Birth:** March 15, 1995  \n",
            "- **Job Title:** Sales Development Representative (SDR)  \n",
            "- **Location:** Austin, Texas  \n",
            "\n",
            "## Insurellm Career Progression\n",
            "- **November 2022** - Joined Insurellm as a Sales Development Representative. Alex Thomson quickly adapted to the team, demonstrating exceptional communication and rapport-building skills.\n",
            "- **January 2023** - Promoted to Team Lead for special projects due to Alex's initiative in driving B2B customer outreach programs.  \n",
            "- **August 2023** - Developed a training module for new SDRs at Insurellm, enhancing onboarding processes based on feedback and strategies that Alex Thomson pioneered.  \n",
            "- **Current** - Continues to excel in the role, leading a small team of 5 SDRs while collaborating closely with the marketing department to identify new lead-generation strategies.  \n",
            "\n",
            "## Annual Performance History  \n",
            "- **2022** - Rated as \"Exceeds Expectations.\" Alex Thomson achieved 150% of the sales target within the first three months.  \n",
            "- **2023** - Rated \"Outstanding.\" Recognized for innovative lead-generation tactics which contributed to a 30% increase in qualified leads for the sales team.  \n",
            "\n",
            "### Highlights:\n",
            "- Consistently maintained a 30-minute response time to inbound leads.\n",
            "- Successfully coordinated webinars for product launches, which attracted over 2,000 potential customers.\n",
            "\n",
            "## Compensation History\n",
            "- **2022**: Base Salary - $55,000 | Bonus - $5,000  \n",
            "- **2023**: Base Salary - $65,000 | Bonus - $10,000 (for exceeding sales targets and exceptional teamwork)  \n",
            "- **Projected for 2024**: Anticipated salary increase due to Alex Thomson's significant contributions and successful completion of leadership training.\n",
            "\n",
            "## Other HR Notes\n",
            "- Alex Thomson is an active member of the Diversity and Inclusion committee at Insurellm and has participated in various community outreach programs.  \n",
            "- Alex has received external training on advanced CRM usage, which has subsequently improved team efficiency and productivity.\n",
            "- Continuous professional development through attending sales conventions and workshops, with plans to pursue certification in Sales Enablement in 2024.\n",
            "- Recognized by peers for promoting a supportive and high-energy team environment, often organizing team-building activities to enhance camaraderie within the SDR department. \n",
            "\n",
            "--- \n",
            "**Comment:** Alex Thomson is considered a cornerstone of Insurellm’s sales team and has a bright future within the organization.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chat(message, history):\n",
        "    messages = [{\"role\": \"system\", \"content\": system_message}] + history\n",
        "    message = add_context(message)\n",
        "    messages.append({\"role\": \"user\", \"content\": message})\n",
        "\n",
        "    stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
        "\n",
        "    response = \"\"\n",
        "    for chunk in stream:\n",
        "        response += chunk.choices[0].delta.content or ''\n",
        "        yield response"
      ],
      "metadata": {
        "id": "VmZtNPfbnziU"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now we will bring this up in Gradio using the Chat interface -\n",
        "\n",
        "A quick and easy way to prototype a chat with an LLM"
      ],
      "metadata": {
        "id": "K_cRCf9An8e_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "view = gr.ChatInterface(chat, type=\"messages\").launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "UznNoRrXn6uS",
        "outputId": "7e990284-35d2-4f43-ce6e-3b11241fe7ba"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://cecf0b8cd35f698d37.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://cecf0b8cd35f698d37.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tqv8_DpUn-Ox"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}