{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzI/qI9Bx0lbNmxikEkYQ3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1uch0/LLM_Udemy_course/blob/main/Chatbot_with_hisotry_and_shop_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rl7cWYyZSah6"
      },
      "outputs": [],
      "source": [
        "#Conversational AI - aka Chatbot!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "\n",
        "import os\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from typing import List\n",
        "#from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "import google.generativeai as fenai\n",
        "#import anthropic\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "fGheOeYNSw28"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install gradio"
      ],
      "metadata": {
        "id": "gDm_tIE4S1Zm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr # oh yeah!"
      ],
      "metadata": {
        "id": "GSytxP3_S5F5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OpenAI API Key (Replace with your own key)\n",
        "\n",
        "api_key = userdata.get('Open_AI_API') ##Open_AI_API It is the API key from OPEN_AI saved in your collab\n",
        "openai = OpenAI(api_key=api_key)\n",
        "openai_api_key = api_key"
      ],
      "metadata": {
        "id": "1lvPEUp4S-r-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize\n",
        "\n",
        "MODEL = 'gpt-4o-mini'"
      ],
      "metadata": {
        "id": "TAWs8h-kTCCs"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"You are a helpful assistant\""
      ],
      "metadata": {
        "id": "LdflM25cUae7"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Please read this! A change from the video:\n",
        "\n",
        "In the video, I explain how we now need to write a function called:\n",
        "\n",
        "`chat(message, history)`\n",
        "\n",
        "Which expects to receive `history` in a particular format, which we need to map to the OpenAI format before we call OpenAI:\n",
        "\n",
        "```\n",
        "[\n",
        "    {\"role\": \"system\", \"content\": \"system message here\"},\n",
        "    {\"role\": \"user\", \"content\": \"first user prompt here\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"the assistant's response\"},\n",
        "    {\"role\": \"user\", \"content\": \"the new user prompt\"},\n",
        "]\n",
        "```\n",
        "\n",
        "But Gradio has been upgraded! Now it will pass in `history` in the exact OpenAI format, perfect for us to send straight to OpenAI.\n",
        "\n",
        "So our work just got easier!\n",
        "\n",
        "We will write a function `chat(message, history)` where:  \n",
        "**message** is the prompt to use  \n",
        "**history** is the past conversation, in OpenAI format  \n",
        "\n",
        "We will combine the system message, history and latest message, then call OpenAI."
      ],
      "metadata": {
        "id": "mMfOd_0kTyY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simpler than in my video - we can easily create this function that calls OpenAI\n",
        "# It's now just 1 line of code to prepare the input to OpenAI!\n",
        "\n",
        "def chat(message, history):\n",
        "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
        "\n",
        "    print(\"History is:\")\n",
        "    print(history)\n",
        "    print(\"And messages is:\")\n",
        "    print(messages)\n",
        "\n",
        "    stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
        "\n",
        "    response = \"\"\n",
        "    for chunk in stream:\n",
        "        response += chunk.choices[0].delta.content or ''\n",
        "        yield response"
      ],
      "metadata": {
        "id": "huGsJaaSTlwF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "V5YbKb-RT1Zd",
        "outputId": "ddac84a9-ae3d-4524-c74b-f994820aaf60"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://90cbc1bd8afb78f084.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://90cbc1bd8afb78f084.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"You are a helpful assistant in a clothes store. You should try to gently encourage \\\n",
        "the customer to try items that are on sale. Hats are 60% off, and most other items are 50% off. \\\n",
        "For example, if the customer says 'I'm looking to buy a hat', \\\n",
        "you could reply something like, 'Wonderful - we have lots of hats - including several that are part of our sales event.'\\\n",
        "Encourage the customer to buy hats if they are unsure what to get.\""
      ],
      "metadata": {
        "id": "8yqaKhWdUH9B"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat(message, history):\n",
        "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
        "\n",
        "    stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
        "\n",
        "    response = \"\"\n",
        "    for chunk in stream:\n",
        "        response += chunk.choices[0].delta.content or ''\n",
        "        yield response"
      ],
      "metadata": {
        "id": "6zUHr9c4UnHN"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "Kno8nKPnUocx",
        "outputId": "604eed61-bacf-495f-842e-07ad9d947555"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://6bdd5ea9636ff9664c.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6bdd5ea9636ff9664c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "system_message += \"\\nIf the customer asks for shoes, you should respond that shoes are not on sale today, \\\n",
        "but remind the customer to look at hats!\" ####eEXAMPLE OF MULTI-SHOT PROMPTING"
      ],
      "metadata": {
        "id": "VRa8JopyUp9t"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "7yalsFHrUwDP",
        "outputId": "de36664f-51e8-418c-dfff-e149d100d072"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://afa6b6e3031c31da9f.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://afa6b6e3031c31da9f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixed a bug in this function brilliantly identified by student Gabor M.!\n",
        "# I've also improved the structure of this function\n",
        "\n",
        "def chat(message, history):\n",
        "\n",
        "    relevant_system_message = system_message\n",
        "    if 'belt' in message:\n",
        "        relevant_system_message += \" The store does not sell belts; if you are asked for belts, be sure to point out other items on sale.\"\n",
        "\n",
        "    if 'shoes' in message:\n",
        "        relevant_system_message += \" The store does not sell shoes; if you are asked for shoes, be sure to point out other items on sale.\"\n",
        "\n",
        "\n",
        "    messages = [{\"role\": \"system\", \"content\": relevant_system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
        "\n",
        "    stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
        "\n",
        "    response = \"\"\n",
        "    for chunk in stream:\n",
        "        response += chunk.choices[0].delta.content or ''\n",
        "        yield response"
      ],
      "metadata": {
        "id": "uRzk8tXWUxkF"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_message += \"\\nIf the customer asks for pants, you should respond that you have only male pants\""
      ],
      "metadata": {
        "id": "753KLigqU0jK"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "_h495yRtU2Nr",
        "outputId": "16a3b758-b1d2-4436-a694-b50281b4df15"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://d977b91844f5182581.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://d977b91844f5182581.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "upLucAAhU3Xg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}